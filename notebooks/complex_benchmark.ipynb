{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sympy import lambdify\n",
    "import sympy as sp\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "import nesymres\n",
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "import omegaconf\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for running benchmarks\n",
    "\n",
    "distribution_type = \"uniform\"\n",
    "# for normal distribution, use mean and standard deviation.\n",
    "# for uniform distribution the range is the min and max values\n",
    "distribution_range = [-.0, 4.0]\n",
    "\n",
    "number_points = 256\n",
    "number_trials = 1 # seeds will be trial number\n",
    "logging = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0 = lambda x: x**5. + x**4. + x**3+x**2 +x**1\n",
    "temp_1 = lambda x: x**4. + x**3+x**2 +x**1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(100,1) * 2 - 1.0\n",
    "\n",
    "np.mean((temp_0(x) - temp_1(x))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_1 = \"1.0*x0/(1.0*x0*1.0*exp(1.0*x0)*1.0*exp(1.0*sin(1.0*x0+1.0))+1.0*exp(1.0*x0)*1.0*exp(1.0*sin(1.0*x0+1.0)))+1.0\"\n",
    "complex_2 = \"1.0*sqrt(1.0*abs(1.0*sqrt(1.0*abs(1.0*x0+1.0))))*1.0*sin(1.0*x0/(1.0*x0+1.0)+1.0/(1.0*x0+1.0))+1.0\"\n",
    "complex_3 = \"1.0*sqrt(1.0*abs(1.0*x0/(1.0*x0+1.0)+1.0/(1.0*x0+1.0)))+1.0*sqrt(1.0*abs(1.0*exp(1.0*x0)))+1.0\"\n",
    "complex_4 = \"1.0*sqrt(1.0*abs(1.0*x0))+1.0/(x0*1.0*sqrt(1.0*abs(1.0*x0))*1.0*sqrt(1.0*abs(1.0*x0)))+1.0\"\n",
    "complex_5 = \"1.0*x0/(1.0*x0*1.0*sqrt(1.0*abs(1.0*log(1.0*x0)))+1.0*sqrt(1.0*abs(1.0*log(1.0*x0))))+1.0\"\n",
    "complex_6 = \"1.0*x0**2*1.0*sqrt(1.0*abs(1.0*x0+1.0))+1.0*x0+1.0*x0/(1.0*x0)+1.0*log(1.0*x0+1.0)+1.0\"\n",
    "complex_7 = \"1.0*sqrt(1.0*abs(1.0*x0*1.0*sqrt(1.0*abs(1.0*x0))/(1.0*x0+1.0)+1.0/(1.0*x0+1.0)))+1.0\"\n",
    "complex_8 = \"1.0*x0**2+1.0*x0+1.0*exp(1.0*x0)/1.0*sqrt(1.0*abs(1.0*sqrt(1.0*abs(1.0*x0+1.0))))+1.0\"\n",
    "\n",
    "sample_meta = {complex_1: (-3, 3., 20),\n",
    "               complex_2: (-3, 3., 20),\n",
    "               complex_3: (-3, 3., 20),\n",
    "               complex_4: (0.1, 4., 20),\n",
    "               complex_5: (1.01, 4, 20),\n",
    "               complex_6: (-.9, 3., 20),\n",
    "               complex_7: (-3, 3., 20),\n",
    "               complex_8: (-3, 3., 20)\n",
    "              }\n",
    "\n",
    "benchmark_eqns = [complex_1, complex_2, complex_3, complex_4, \\\n",
    "        complex_5, complex_6, complex_7, complex_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8c16c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize equations\n",
    "\n",
    "plt.figure()\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "    x = np.arange(bottom, top, step_size)\n",
    "    \n",
    "    plt.plot(x, my_fn(x), label = f\"complex-{1+number}\")\n",
    "    print(x.shape, my_fn(x).shape)\n",
    "    print(f\" {1+number} {sp.simplify(fn)} \\n\")\n",
    "    print(f\"  {sp.expand(fn)} \\n\")\n",
    "    print(fn)\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(\"complex benchmark equations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = \"eqn, seed, pred, target, correct, mse, method, range_low, range_high, number_points\"\n",
    "my_method = \"PySR\"\n",
    "eval_tag = f\"eval_complex_{my_method}_{int(time.time())}\"\n",
    "\n",
    "if logging:\n",
    "    with open(f\"{eval_tag}.csv\", \"w\") as f:\n",
    "        f.write(columns)\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "accuracies = []\n",
    "all_mses = []\n",
    "all_mse_sds = []\n",
    "for hh, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    equivalents = []\n",
    "    mses = []\n",
    "    for trial in range(number_trials):\n",
    "\n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "        \n",
    "        my_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        \n",
    "        (bottom, top, number_samples) = sample_meta[eqn]\n",
    "        x = np.random.rand(number_samples, 1) \\\n",
    "                * (top-bottom) \\\n",
    "                + bottom\n",
    "        y = my_fn(x)\n",
    "        \n",
    "        model = PySRRegressor(\n",
    "            niterations=10,\n",
    "            binary_operators=[\"+\", \"*\"],\n",
    "            unary_operators=[\n",
    "                \"cos\",\n",
    "                \"exp\",\n",
    "                \"sin\",\n",
    "                \"inv(x) = 1/x\"  # Custom operator (julia syntax)\n",
    "            ],\n",
    "            model_selection=\"best\",\n",
    "            deterministic = True,\n",
    "            procs = 0,\n",
    "            multithreading = False,\n",
    "            random_state = trial,\n",
    "            verbosity=0,\n",
    "            loss=\"loss(x, y) = (x - y)^2\",  # Custom loss function (julia syntax)\n",
    "        )\n",
    "        \n",
    "        model.fit(x, y)\n",
    "        \n",
    "        if \"bs\" in model.get_best()[\"equation\"]:\n",
    "            print(\"abs detected\")\n",
    "        \n",
    "        if (x >= 0).all():\n",
    "            # remove abs() if input only consists of positive numbers\n",
    "            if \"abs\" in model.get_best()[\"equation\"]:\n",
    "                best_eqn = sp.simplify(model.get_best()[\"equation\"]\\\n",
    "                                       .replace(\"inv(\", \"1./(\").replace(\"abs(x\", \"(x\"))\n",
    "                best_fn = sp.lambdify(\"x0\", expr=model.get_best()[\"equation\"]\\\n",
    "                                      .replace(\"inv(\", \"1./(\").replace(\"abs(x\", \"(x\"))\n",
    "                \n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            else:\n",
    "                best_eqn = sp.simplify(model.get_best()[\"equation\"].replace(\"inv(\", \"1./(\"))\n",
    "                best_fn = sp.lambdify(\"x0\", expr=model.get_best()[\"equation\"].replace(\"inv(\", \"1./(\"))\n",
    "                \n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            if \"abs\" in eqn:\n",
    "                tgt_eqn = sp.simplify(eqn.replace(\"abs\", \"\"))\n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn.replace(\"abs\", \"\"))\n",
    "            else:\n",
    "                tgt_eqn = sp.simplify(eqn)\n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        else:\n",
    "            best_eqn = sp.simplify(model.get_best()[\"equation\"].replace(\"inv(\", \"1./(\"))\n",
    "            best_fn = sp.lambdify(\"x0\", expr=model.get_best()[\"equation\"].replace(\"inv(\", \"1./(\"))\n",
    "            \n",
    "            tgt_eqn = sp.simplify(eqn)\n",
    "            tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            \n",
    "        is_correct = sp.simplify(best_eqn - tgt_eqn) == 0\n",
    "        my_mse = np.mean((tgt_fn(x) - best_fn(x))**2)\n",
    "        \n",
    "        equivalents.append(is_correct)\n",
    "        mses.append(my_mse)\n",
    "        \n",
    "        wright = \"correct\" if equivalents[-1] else \"incorrect\"\n",
    "        \n",
    "        correct = 1 if equivalents[-1] else 0\n",
    "        try:\n",
    "            msg = f\"eqn {hh+1}, trial {trial} predicted {wright} equation {best_eqn} for target {tgt_eqn}\"\n",
    "            msg += f\" with mse {my_mse:.3}\"\n",
    "        except:\n",
    "            msg = \"\"\n",
    "        print(msg)\n",
    "        \n",
    "        #columns = \"eqn, seed, pred, target, correct, mse, method, range_low, range_high, number_points\"\n",
    "        if logging:\n",
    "            results = f\"{eqn}, {hh}, {best_eqn}, {tgt_eqn}, {correct}, {my_mse},\"\\\n",
    "                    f\" {my_method}, {bottom}, {top}, {number_samples}\"\n",
    "\n",
    "            with open(f\"{eval_tag}.csv\", \"a\") as f:\n",
    "                f.write(results)\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    msg = f\"accuracy for equation {hh+1}: {np.mean(equivalents)}\"\\\n",
    "            f\" with mean mse: {np.mean(mses):3}\"\n",
    "    print(msg)\n",
    "    accuracies.append(np.mean(equivalents))\n",
    "    all_mses.append(np.mean(mses))\n",
    "    all_mse_sds.append(np.std(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_method = \"PySR\"\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "\n",
    "for ii, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    msg += f\"\\n  Complex-{ii+1},  accuracy: {accuracies[ii]:5f}, mse: {all_mses[ii]:.5} +/- {all_mse_sds[ii]:.5}\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "\n",
    "if logging:\n",
    "    summary_file = f\"{eval_tag}_summary.txt\"\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        f.write(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to point to directory containing \n",
    "#  weights/100M.ckpt and jupyter/100M/eq_settings.json and jupyter/100M/config.yaml\n",
    "my_method = \"NSRTS\"\n",
    "eval_tag = f\"eval_complex_{my_method}_{int(time.time())}\"\n",
    "columns = \"eqn, seed, pred, target, correct, mse, method, range_low, range_high, number_points\"\n",
    "\n",
    "if logging:\n",
    "    with open(f\"{eval_tag}.csv\", \"w\") as f:\n",
    "        f.write(columns)\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "\n",
    "nsrts_dir = \"../../nsrts\"\n",
    "\n",
    "json_filepath = os.path.join(nsrts_dir, \"jupyter\", \"100M\", \"eq_setting.json\")\n",
    "with open(json_filepath, 'r') as json_file:\n",
    "    eq_setting = json.load(json_file)\n",
    "     \n",
    "cfg_filepath = os.path.join(nsrts_dir, \"jupyter\", \"100M\", \"config.yaml\")\n",
    "cfg = omegaconf.OmegaConf.load(cfg_filepath)\n",
    "\n",
    "weights_path = os.path.join(nsrts_dir, \"weights\", \"100M.ckpt\")\n",
    "    \n",
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n",
    "\n",
    "# adjust this parameter up for greater accuracy and longer runtime\n",
    "cfg.inference.beam_size = 1\n",
    "\n",
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )\n",
    "\n",
    "## Load equation configuration and architecture configuration\n",
    "accuracies = []\n",
    "all_mses = []\n",
    "all_mse_sds = []\n",
    "\n",
    "for hh, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    equivalents = []\n",
    "    mses = []\n",
    "    for trial in range(number_trials):\n",
    "\n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "\n",
    "        \n",
    "        ## Load architecture, set into eval mode, and pass the config parameters\n",
    "        model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "        model.eval()\n",
    "        if torch.cuda.is_available(): \n",
    "            model.to(torch.device(\"cuda:1\")) \n",
    "            \n",
    "        fitfunc = partial(model.fitfunc, cfg_params=params_fit)\n",
    "\n",
    "        my_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        \n",
    "        \n",
    "        print(x.shape, y.shape)\n",
    "        # work-around for occasional catastrophic failure\n",
    "        output = {\"best_bfgs_preds\": []}\n",
    "        \n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "        \n",
    "        while len(output[\"best_bfgs_preds\"]) == 0:\n",
    "        \n",
    "            (bottom, top, number_samples) = sample_meta[eqn]\n",
    "            x = np.random.rand(number_samples, 1) \\\n",
    "                    * (top-bottom) \\\n",
    "                    + bottom\n",
    "            y = my_fn(x)\n",
    "            \n",
    "            x = torch.tensor(x)\n",
    "            y = torch.tensor(y)\n",
    "            \n",
    "            try:\n",
    "                output = fitfunc(x, y.squeeze()) \n",
    "            except:\n",
    "                output = fitfunc(x, y.squeeze()) \n",
    "            \n",
    "        if (x >= 0).all():\n",
    "            print(\"removing abs\")\n",
    "            # remove abs() if input only consists of positive numbers\n",
    "            no_abs = output[\"best_bfgs_preds\"][0].replace(\"Abs\",\"\")\n",
    "            best_eqn = sp.simplify(no_abs.replace(\"x_1\", \"x0\"))\n",
    "            if \"abs\" in eqn:\n",
    "                tgt_eqn = sp.simplify(eqn.replace(\"abs\", \"\"))\n",
    "            else:\n",
    "                tgt_eqn = sp.simplify(eqn)\n",
    "        else:\n",
    "            best_eqn = sp.simplify(output[\"best_bfgs_preds\"][0].replace(\"x_1\", \"x0\"))\n",
    "            tgt_eqn = sp.simplify(eqn)\n",
    "        \n",
    "        is_correct = sp.simplify(best_eqn - tgt_eqn) == 0\n",
    "        my_mse = np.mean(((sp.lambdify(\"x0\", expr=tgt_eqn)(x) - sp.lambdify(\"x0\", expr=best_eqn)(x))**2).cpu().numpy())\n",
    "        \n",
    "        equivalents.append(is_correct)\n",
    "        mses.append(my_mse)\n",
    "        \n",
    "        wright = \"correct\" if equivalents[-1] else \"incorrect\"\n",
    "        correct = 1 if equivalents[-1] else 0\n",
    "        \n",
    "        msg = f\"eqn {hh}, trial {trial} predicted {wright} equation {best_eqn} for target {tgt_eqn}\"\n",
    "        print(msg)\n",
    "        \n",
    "        #columns = \"eqn, seed, pred, target, correct, mse, method, range_low, range_high, number_points\"\n",
    "        if logging:\n",
    "            results = f\"{eqn}, {hh}, {best_eqn}, {tgt_eqn}, {correct}, {my_mse},\"\\\n",
    "                    f\" {my_method}, {bottom}, {top}, {number_samples}\"\n",
    "\n",
    "            with open(f\"{eval_tag}.csv\", \"a\") as f:\n",
    "                f.write(results)\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        \n",
    "    msg = f\"accuracy for equation {hh+1}: {np.mean(equivalents)}\"\\\n",
    "            f\" with mean mse: {np.mean(mses):3}\"\n",
    "    print(msg)\n",
    "    accuracies.append(np.mean(equivalents))\n",
    "    all_mses.append(np.mean(mses))\n",
    "    all_mse_sds.append(np.std(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_method = \"NSRTS\"\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "\n",
    "for ii, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    msg += f\"\\n  Complex-{ii+1},  accuracy: {accuracies[ii]:4f}, mse: {all_mses[ii]} +/- {all_mse_sds[ii]}\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "\n",
    "if logging:\n",
    "    summary_file = f\"{eval_tag}_summary.txt\"\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        f.write(msg)\n",
    "print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
