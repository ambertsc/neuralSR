{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sympy import lambdify\n",
    "import sympy as sp\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "import nesymres\n",
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "import omegaconf\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for running benchmarks\n",
    "\n",
    "distribution_type = \"uniform\"\n",
    "# for normal distribution, use mean and standard deviation.\n",
    "# for uniform distribution the range is the min and max values\n",
    "distribution_range = [0, 10.0]\n",
    "number_points = 500\n",
    "number_trials = 100 # seeds will be trial number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nguyen_1 = \"x0**3 + x0**2 + x0\"\n",
    "nguyen_2 = \"x0**4 + x0**3 + x0**2 + x0\"\n",
    "nguyen_3 = \"x0**5 + x0**4 + x0**3 + x0**2 + x0\"\n",
    "nguyen_4 = \"x0**6 + x0**5 + x0**4 + x0**3 + x0**2 + x0\"\n",
    "nguyen_5 = \"sin(x0**2) * cos(x0) - 1\"\n",
    "nguyen_6 = \"sin(x0) + sin(x0+x0**2)\" \n",
    "nguyen_7 = \"log(x0+1) + log(x0**2 + 1) \"\n",
    "nguyen_8 = \"x0**(1/2)\"\n",
    "\n",
    "nguyen_benchmarks = [nguyen_1, nguyen_2, nguyen_3, nguyen_4, \\\n",
    "        nguyen_5, nguyen_6, nguyen_7, nguyen_8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize equations\n",
    "\n",
    "fn = sp.lambdify(\"x0\", expr=nguyen_2)\n",
    "plt.figure()\n",
    "for number, fn in enumerate(nguyen_benchmarks):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    step_size = (distribution_range[1] - distribution_range[0])/100\n",
    "    x = np.arange(distribution_range[0], distribution_range[1], step_size)\n",
    "    \n",
    "    plt.plot(x, my_fn(x), label = f\"Nguyen-{number}\")\n",
    "    print(x.shape, my_fn(x).shape)\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(\"Nguyen benchmark equations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for hh, eqn in enumerate(nguyen_benchmarks):\n",
    "    \n",
    "    equivalents = []\n",
    "    \n",
    "    for trial in range(number_trials):\n",
    "\n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "\n",
    "        model = PySRRegressor(\n",
    "            niterations=10,\n",
    "            binary_operators=[\"+\", \"*\"],\n",
    "            unary_operators=[\n",
    "                \"cos\",\n",
    "                \"exp\",\n",
    "                \"sin\",\n",
    "                \"inv(x) = 1/x\"  # Custom operator (julia syntax)\n",
    "            ],\n",
    "            model_selection=\"best\",\n",
    "            deterministic = True,\n",
    "            procs = 0,\n",
    "            multithreading = False,\n",
    "            random_state = trial,\n",
    "            verbosity=0,\n",
    "            loss=\"loss(x, y) = (x - y)^2\",  # Custom loss function (julia syntax)\n",
    "        )\n",
    "\n",
    "\n",
    "        my_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        x = np.random.rand(number_points, 1) \\\n",
    "                * (distribution_range[1]-distribution_range[0]) \\\n",
    "                - distribution_range[0]\n",
    "        y = my_fn(x)\n",
    "        model.fit(x, y)\n",
    "        \n",
    "        best_eqn = sp.simplify(model.get_best()[\"equation\"])\n",
    "        tgt_eqn = sp.simplify(eqn)\n",
    "        is_correct = sp.simplify(best_eqn - tgt_eqn) == 0\n",
    "        equivalents.append(is_correct)\n",
    "        \n",
    "        wright = \"correct\" if equivalents[-1] else \"incorrect\"\n",
    "        try:\n",
    "            msg = f\"eqn {hh}, trial {trial} predicted {wright} equation {best_eqn} for target {tgt_eqn}\"\n",
    "        except:\n",
    "            msg = \"\"\n",
    "        print(msg)\n",
    "        \n",
    "    msg = f\"accuracy for equation {eqn}: {np.mean(equivalents)}\"\n",
    "    print(msg, equivalents)\n",
    "    accuracies.append(np.mean(equivalents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_method = \"PySR\"\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "\n",
    "for ii, eqn in enumerate(nguyen_benchmarks):\n",
    "    \n",
    "    msg += f\"\\n  Nguyen-{ii+1}  accuracy: {accuracies[ii]:4f}\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "    \n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to point to directory containing \n",
    "#  weights/100M.ckpt and jupyter/100M/eq_settings.json and jupyter/100M/config.yaml\n",
    "nsrts_dir = \"../../nsrts\"\n",
    "\n",
    "\n",
    "json_filepath = os.path.join(nsrts_dir, \"jupyter\", \"100M\", \"eq_setting.json\")\n",
    "with open(json_filepath, 'r') as json_file:\n",
    "    eq_setting = json.load(json_file)\n",
    "     \n",
    "cfg_filepath = os.path.join(nsrts_dir, \"jupyter\", \"100M\", \"config.yaml\")\n",
    "cfg = omegaconf.OmegaConf.load(cfg_filepath)\n",
    "\n",
    "weights_path = os.path.join(nsrts_dir, \"weights\", \"100M.ckpt\")\n",
    "    \n",
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n",
    "\n",
    "# adjust this parameter up for greater accuracy and longer runtime\n",
    "cfg.inference.beam_size = 1\n",
    "\n",
    "params_fit = FitParams(word2id=eq_setting[\"word2id\"], \n",
    "                            id2word={int(k): v for k,v in eq_setting[\"id2word\"].items()}, \n",
    "                            una_ops=eq_setting[\"una_ops\"], \n",
    "                            bin_ops=eq_setting[\"bin_ops\"], \n",
    "                            total_variables=list(eq_setting[\"total_variables\"]),  \n",
    "                            total_coefficients=list(eq_setting[\"total_coefficients\"]),\n",
    "                            rewrite_functions=list(eq_setting[\"rewrite_functions\"]),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )\n",
    "\n",
    "## Load equation configuration and architecture configuration\n",
    "accuracies = []\n",
    "\n",
    "for hh, eqn in enumerate(nguyen_benchmarks):\n",
    "    \n",
    "    equivalents = []\n",
    "    \n",
    "    for trial in range(number_trials):\n",
    "\n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "\n",
    "\n",
    "\n",
    "        ## Load architecture, set into eval mode, and pass the config parameters\n",
    "        model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "        model.eval()\n",
    "        if torch.cuda.is_available(): \n",
    "            model.to(torch.device(\"cuda:1\")) \n",
    "            \n",
    "        fitfunc = partial(model.fitfunc, cfg_params=params_fit)\n",
    "\n",
    "        my_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        \n",
    "        \n",
    "        print(x.shape, y.shape)\n",
    "        # work-around for occasional catastrophic failure\n",
    "        output = {\"best_bfgs_preds\": []}\n",
    "        \n",
    "        while len(output[\"best_bfgs_preds\"]) == 0:\n",
    "            \n",
    "            x = np.random.rand(number_points, 1) \\\n",
    "                * (distribution_range[1]-distribution_range[0]) \\\n",
    "                - distribution_range[0]\n",
    "            y = my_fn(x)\n",
    "\n",
    "            x = torch.tensor(x)\n",
    "            y = torch.tensor(y)\n",
    "            \n",
    "            output = fitfunc(x, y.squeeze()) \n",
    "        \n",
    "        best_eqn = sp.simplify(output[\"best_bfgs_preds\"][0].replace(\"x_1\", \"x0\"))\n",
    "        \n",
    "        tgt_eqn = sp.simplify(eqn)\n",
    "        is_correct = sp.simplify(best_eqn - tgt_eqn) == 0\n",
    "        equivalents.append(is_correct)\n",
    "        \n",
    "        wright = \"correct\" if equivalents[-1] else \"incorrect\"\n",
    "        msg = f\"eqn {hh}, trial {trial} predicted {wright} equation {best_eqn} for target {tgt_eqn}\"\n",
    "        print(msg)\n",
    "        \n",
    "    msg = f\"accuracy for equation {eqn}: {np.mean(equivalents)}\"\n",
    "    print(msg, equivalents)\n",
    "    accuracies.append(np.mean(equivalents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_method = \"NSRTS\"\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "\n",
    "for ii, eqn in enumerate(nguyen_benchmarks):\n",
    "    \n",
    "    msg += f\"\\n  Nguyen-{ii+1}  accuracy: {accuracies[ii]:4f}\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "    \n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results with 500 sample points per equation, 100 trials with 100 different random seeds, default settings\n",
    "# and random uniform distribution from 0 to 10.0\n",
    "\n",
    "\"\"\"\n",
    "PySR accuracies\n",
    "\n",
    "  Nguyen-1  accuracy: 0.890000\n",
    "  x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-2  accuracy: 0.150000\n",
    "  x0**4 + x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-3  accuracy: 0.160000\n",
    "  x0**5 + x0**4 + x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-4  accuracy: 0.000000\n",
    "  x0**6 + x0**5 + x0**4 + x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-5  accuracy: 0.110000\n",
    "  sin(x0**2)*cos(x0) - 1 \n",
    "\n",
    "  Nguyen-6  accuracy: 0.880000\n",
    "  sin(x0) + sin(x0**2 + x0) \n",
    "\n",
    "  Nguyen-7  accuracy: 0.000000\n",
    "  log(x0 + 1) + log(x0**2 + 1) \n",
    "\n",
    "  Nguyen-8  accuracy: 0.000000\n",
    "  sqrt(x0) \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
